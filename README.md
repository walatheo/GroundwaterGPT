# GroundwaterGPT

[![CI Pipeline](https://github.com/walatheo/GroundwaterGPT/actions/workflows/ci.yml/badge.svg)](https://github.com/walatheo/GroundwaterGPT/actions)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**An AI-powered groundwater research platform with transparent, explainable architecture.**

---

## ğŸ¯ Project Overview

GroundwaterGPT is a **whitebox AI system** that combines:
- **Deep Research Agent**: LLM-powered research with source verification
- **Continuous Learning**: Auto-growing knowledge base from USGS data
- **ML Predictions**: 7-day groundwater level forecasts (93% accuracy)
- **Interactive Dashboard**: Trend visualization

### Key Features

| Feature | Description |
|---------|-------------|
| ğŸ“š **Query Mode** | Instant search of knowledge base (USGS data, PDFs) |
| ğŸ”¬ **Research Mode** | Deep web research with verified sources |
| ğŸ§  **Auto-Learning** | Continuously grows knowledge from new data |
| ğŸ“Š **Predictions** | ML models for groundwater level forecasting |
| âœ… **Whitebox** | All decisions are transparent and explainable |

---

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone https://github.com/walatheo/GroundwaterGPT.git
cd GroundwaterGPT

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Start the Research Interface

```bash
streamlit run research_chat.py --server.port 8502
```

Open http://localhost:8502 to access:
- **Query Mode**: Fast search of USGS data and hydrogeology documents
- **Research Mode**: Deep research with web search and auto-learning

### 3. Run Continuous Learning

```bash
python continuous_learning.py
```

Fetches data from 40+ Florida aquifer monitoring sites and adds to knowledge base.

### 4. View the Dashboard

```bash
open plots/dashboard.html
```

---

## ğŸ“Š Data Sources

### Groundwater Data
- **Source:** USGS National Water Information System (NWIS)
- **Site:** 263314081472201 (Fort Myers, Surficial Aquifer)
- **Period:** 2014-01-01 to 2023-12-31
- **Records:** 3,650 daily measurements
- **Variable:** Depth to water level (feet below surface)

### Reference Documents
Three hydrogeology PDFs are embedded in ChromaDB for future RAG integration:
- `a-glossary-of-hydrogeology.pdf`
- `age-dating-young-groundwater.pdf`
- `a-conceptual-overview-of-surface-and-near-surface-brines-and-evaporite-minerals.pdf`

---

## ğŸ“ Project Structure

```
GroundwaterGPT/
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ download_data.py          # USGS data fetcher
â”œâ”€â”€ train_groundwater.py      # Model training pipeline
â”œâ”€â”€ dashboard.py              # Interactive dashboard generator
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ DEVELOPMENT_GUIDE.md      # Best practices & standards
â”œâ”€â”€ PROJECT_STATUS.md         # Roadmap & current status
â”‚
â”œâ”€â”€ data/                     # Data files (gitignored)
â”‚   â”œâ”€â”€ groundwater.csv       # USGS measurements
â”‚   â”œâ”€â”€ forecast.csv          # 30-day predictions
â”‚   â””â”€â”€ model_comparison.csv  # Model metrics
â”‚
â”œâ”€â”€ models/                   # Trained models (gitignored)
â”‚   â””â”€â”€ best_gradient_boosting.joblib
â”‚
â”œâ”€â”€ plots/                    # Visualizations (gitignored)
â”‚   â”œâ”€â”€ dashboard.html        # Interactive dashboard
â”‚   â””â”€â”€ model_predictions.png # Prediction accuracy
â”‚
â”œâ”€â”€ tests/                    # Test suite
â”‚   â”œâ”€â”€ unit/                 # Feature engineering tests
â”‚   â”œâ”€â”€ model/                # Model performance tests
â”‚   â””â”€â”€ data/                 # Data quality tests
â”‚
â”œâ”€â”€ .github/workflows/        # CI/CD pipeline
â”‚   â””â”€â”€ ci.yml
â”‚
â””â”€â”€ chroma_db/                # Vector store for RAG
```

---

## ğŸ—ï¸ Whitebox Architecture

GroundwaterGPT follows **whitebox principles** - all AI decisions are transparent and explainable.

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRESENTATION LAYER                        â”‚
â”‚  research_chat.py (Streamlit UI)                            â”‚
â”‚  - Query Mode: Fast KB search                               â”‚
â”‚  - Research Mode: Deep web research                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENT LAYER                              â”‚
â”‚  agent/research_agent.py (Deep Research Agent)              â”‚
â”‚  - Query optimization                                       â”‚
â”‚  - Iterative search                                         â”‚
â”‚  - Insight extraction                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KNOWLEDGE LAYER                          â”‚
â”‚  agent/knowledge.py (ChromaDB + Embeddings)                 â”‚
â”‚  - Vector search (BAAI/bge-small-en-v1.5)                  â”‚
â”‚  - Document storage                                         â”‚
â”‚  continuous_learning.py (Data Collection)                   â”‚
â”‚  - USGS API integration                                     â”‚
â”‚  - Auto-ingestion                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERIFICATION LAYER                       â”‚
â”‚  agent/source_verification.py                               â”‚
â”‚  - Trust scoring (0.0 - 1.0)                               â”‚
â”‚  - Source categorization                                    â”‚
â”‚  - Approval/rejection logic                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Trust Hierarchy

All sources are scored transparently:

| Priority | Source Type | Score | Example |
|----------|-------------|-------|---------|
| 1 | USGS Data | 1.00 | waterdata.usgs.gov |
| 2 | Research Papers | 0.95 | DOI links, journals |
| 3 | Government | 0.90 | .gov domains |
| 4 | Academic | 0.85 | .edu domains |
| 5 | Reference | 0.70 | Wikipedia |
| 6 | Unknown | 0.50 | Unverified |
| 7 | Untrusted | 0.00 | Blocked |

---

## ğŸ§ª Testing

Run the full test suite:

```bash
pytest tests/ -v
```

Run with coverage:

```bash
pytest tests/ --cov=. --cov-report=html
open htmlcov/index.html
```

### Test Categories

| Category | Tests | Purpose |
|----------|-------|---------|
| `tests/unit/` | 9 | Feature engineering, data leakage prevention |
| `tests/model/` | 10 | Model performance thresholds |
| `tests/data/` | 13 | Data quality and schema validation |

**Current Status:** 32/32 tests passing âœ…

---

## ğŸ”§ Development

### Pre-commit Hooks

Install hooks for automatic code quality checks:

```bash
pip install pre-commit
pre-commit install
```

### Code Style

- **Formatter:** Black (line length 100)
- **Linter:** Flake8
- **Import sorting:** isort
- **Type hints:** Required for public functions

### Branch Strategy

```
main (protected)
  â†‘ PR + CI must pass
develop
  â†‘ feature branches
feature/your-feature
```

---

## ğŸ“ˆ Roadmap

| Phase | Status | Focus |
|-------|--------|-------|
| 1. Foundation | âœ… Complete | Data pipeline, ML model, dashboard |
| 2. Quality | ğŸ”„ Current | CI/CD, testing, documentation |
| 3. Enhancement | ğŸ“‹ Planned | Multi-horizon forecasting, confidence intervals |
| 4. Research | ğŸ“‹ Planned | RAG integration, automated reports |
| 5. Production | ğŸ“‹ Planned | API, web hosting, alerts |

See [PROJECT_STATUS.md](PROJECT_STATUS.md) for detailed roadmap.

---

## ğŸ“š Documentation

- **[DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md)** - Coding standards, roles, schedule
- **[PROJECT_STATUS.md](PROJECT_STATUS.md)** - Current status and roadmap

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Make changes with tests
4. Run quality checks (`pytest && flake8`)
5. Commit with conventional message (`feat: add new feature`)
6. Push and create PR

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ‘¤ Author

**walatheo** - [GitHub](https://github.com/walatheo)

*Florida Gulf Coast University*

---

## ğŸ™ Acknowledgments

- **USGS** - Groundwater monitoring data via NWIS
- **Copernicus Climate Data Store** - ERA5 reanalysis data
- **scikit-learn** - Machine learning framework
- **Plotly** - Interactive visualizations
